{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_xhvUO10XD6"
   },
   "source": [
    "# 畳み込みニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82Sx06lGrg3K"
   },
   "source": [
    "## 基本的な事柄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-S6ghDZpmSG"
   },
   "source": [
    "画像データを処理することが得意なニューラルネットワークである畳み込みニューラルネットワーク（convolutional neural network（CNN））とそれに関する基本的な事柄をまとめます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isuh1_iiygT0"
   },
   "source": [
    "### CNN とは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtIMcWPodXRj"
   },
   "source": [
    "ほげ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3mzuNEjy5to"
   },
   "source": [
    "### 畳み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7fpi958zLiS"
   },
   "source": [
    "ほげ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hezey89MynbX"
   },
   "source": [
    "### プーリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IG4DcIBO42U_"
   },
   "source": [
    "ほげ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RlLdfs5ynbW"
   },
   "source": [
    "## CNN の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZpHl3AlpmSN"
   },
   "source": [
    "この節では CNN の使い方を紹介します．前章の MLP の実装を拡張する方法で CNN を実装します．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9N2tV28sR6t2"
   },
   "source": [
    "### 基となる MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gSBTJTOR6t3"
   },
   "source": [
    "以下のものは前章の最後で紹介した MLP を実装するためのものです．MNIST に対する予測器を MLP を用いて構築し，さらに構築した MLP のパラメータ情報を保存するものです．学習の際には学習曲線を出力し，また，早期停止によって過学習を避けるようにしています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W57xClNsjinH"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def main():\n",
    "    # GPUの使用の設定．\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ハイパーパラメータの設定．\n",
    "    MAXEPOCH = 50\n",
    "    MINIBATCHSIZE = 500\n",
    "    UNITSIZE = 500\n",
    "    PATIENCE = 5\n",
    "\n",
    "    # データの読み込みと前処理．\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    learn_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    # トレーニングセットとバリデーションセットの分割．\n",
    "    train_dataset, valid_dataset = torch.utils.data.random_split(learn_dataset, [int(len(learn_dataset) * 0.9), int(len(learn_dataset) * 0.1)])\n",
    "\n",
    "    # データローダーの設定．\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=MINIBATCHSIZE, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=len(valid_dataset), shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "    # ネットワークの定義．\n",
    "    model = Network(UNITSIZE, len(learn_dataset.classes)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # 学習ループ．\n",
    "    liepoch, litraincost, livalidcost = [], [], []\n",
    "    patiencecounter, bestvalue = 0, 100000\n",
    "    for epoch in range(1, MAXEPOCH + 1):\n",
    "        # トレーニング．\n",
    "        model.train() # ドロップアウト等は動作するモード．\n",
    "        traincost = 0.0\n",
    "        for tx, tt in train_loader:\n",
    "            tx, tt = tx.to(device), tt.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            ty = model(tx)\n",
    "            loss = criterion(ty, tt)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            traincost += loss.item()\n",
    "        traincost /= len(train_loader) # このlen(train_loader)はミニバッチの個数．\n",
    "        # バリデーション．\n",
    "        model.eval() # ドロップアウト等は動作しないモード．\n",
    "        validcost = 0.0\n",
    "        with torch.no_grad():\n",
    "            for tx, tt in valid_loader:\n",
    "                tx, tt = tx.to(device), tt.to(device)\n",
    "                ty = model(tx)\n",
    "                loss = criterion(ty, tt)\n",
    "                validcost += loss.item()\n",
    "        validcost /= len(valid_loader)\n",
    "        # 学習過程の出力．\n",
    "        print(\"Epoch {:4d}: Training cost= {:7.4f} Validation cost= {:7.4f}\".format(epoch, traincost, validcost))\n",
    "        liepoch.append(epoch)\n",
    "        litraincost.append(traincost)\n",
    "        livalidcost.append(validcost)\n",
    "        if validcost < bestvalue:\n",
    "            bestvalue = validcost\n",
    "            patiencecounter = 0\n",
    "            torch.save(model.state_dict(), \"mlp-mnist-model.pt\") # モデルを保存するための記述．\n",
    "        else:\n",
    "            patiencecounter += 1\n",
    "        if patiencecounter == PATIENCE:\n",
    "            break\n",
    "\n",
    "    # 学習曲線の描画\n",
    "    plt.plot(liepoch,litraincost,label=\"Training\")\n",
    "    plt.plot(liepoch,livalidcost,label=\"Validation\")\n",
    "    plt.ylim(0,0.2)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, UNITSIZE, OUTPUTSIZE):\n",
    "        super(Network, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.d1 = nn.Linear(28*28, UNITSIZE)\n",
    "        self.d2 = nn.Linear(UNITSIZE, OUTPUTSIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.d1(x))\n",
    "        x = self.d2(x)\n",
    "        return x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcCLBTuajHb_"
   },
   "source": [
    "### CNN の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ek1hTowAjM4C"
   },
   "source": [
    "これまでにオブジェクト指向の書き方を学びましたが，その有用性をこのコードの改造で実感できます．ここでは，以上の MLP の計算で定義したクラス，`Network` のみを CNN のものに置き換えることで，CNN を実装します．以下のようにします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEMk4qdMjWwg"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def main():\n",
    "    # GPUの使用の設定．\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ハイパーパラメータの設定．\n",
    "    MAXEPOCH = 50\n",
    "    MINIBATCHSIZE = 500\n",
    "    PATIENCE = 5\n",
    "\n",
    "    # データの読み込みと前処理．\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    learn_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    # トレーニングセットとバリデーションセットの分割．\n",
    "    train_dataset, valid_dataset = torch.utils.data.random_split(learn_dataset, [int(len(learn_dataset) * 0.9), int(len(learn_dataset) * 0.1)])\n",
    "\n",
    "    # データローダーの設定．\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=MINIBATCHSIZE, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=len(valid_dataset), shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "    # ネットワークの定義．\n",
    "    model = Network(len(learn_dataset.classes)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # 学習ループ．\n",
    "    liepoch, litraincost, livalidcost = [], [], []\n",
    "    patiencecounter, bestvalue = 0, 100000\n",
    "    for epoch in range(1, MAXEPOCH + 1):\n",
    "        # トレーニング．\n",
    "        model.train() # ドロップアウト等は動作するモード．\n",
    "        traincost = 0.0\n",
    "        for tx, tt in train_loader:\n",
    "            tx, tt = tx.to(device), tt.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            ty = model(tx)\n",
    "            loss = criterion(ty, tt)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            traincost += loss.item()\n",
    "        traincost /= len(train_loader) # このlen(train_loader)はミニバッチの個数．\n",
    "        # バリデーション．\n",
    "        model.eval() # ドロップアウト等は動作しないモード．\n",
    "        validcost = 0.0\n",
    "        with torch.no_grad():\n",
    "            for tx, tt in valid_loader:\n",
    "                tx, tt = tx.to(device), tt.to(device)\n",
    "                ty = model(tx)\n",
    "                loss = criterion(ty, tt)\n",
    "                validcost += loss.item()\n",
    "        validcost /= len(valid_loader)\n",
    "        # 学習過程の出力．\n",
    "        print(\"Epoch {:4d}: Training cost= {:7.4f} Validation cost= {:7.4f}\".format(epoch, traincost, validcost))\n",
    "        liepoch.append(epoch)\n",
    "        litraincost.append(traincost)\n",
    "        livalidcost.append(validcost)\n",
    "        if validcost < bestvalue:\n",
    "            bestvalue = validcost\n",
    "            patiencecounter = 0\n",
    "            torch.save(model.state_dict(), \"cnn-mnist-model.pt\")\n",
    "        else:\n",
    "            patiencecounter += 1\n",
    "        if patiencecounter == PATIENCE:\n",
    "            break\n",
    "\n",
    "    # 学習曲線の描画\n",
    "    plt.plot(liepoch,litraincost,label=\"Training\")\n",
    "    plt.plot(liepoch,livalidcost,label=\"Validation\")\n",
    "    plt.ylim(0,0.2)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, OUTPUTSIZE):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2) # 畳み込み層1: 1チャネル入力, 32チャネル出力, カーネルサイズ5, ストライド1, パディング2．\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2) # 畳み込み層2: 32チャネル入力, 64チャネル出力, カーネルサイズ5, ストライド1, パディング2．\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # プーリング層: カーネルサイズ2, ストライド2．\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 500) # 全結合層1: 64*7*7入力, 500出力．\n",
    "        self.fc2 = nn.Linear(500, OUTPUTSIZE) # 全結合層2（出力層）: 500入力, 出力サイズ（クラス数）．\n",
    "\n",
    "    def forward(self, x): # 入力: [バッチサイズ, 1, 28, 28]\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # [バッチサイズ, 32, 14, 14]\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # [バッチサイズ, 64, 7, 7]\n",
    "        x = x.view(-1, 64 * 7 * 7)  # [バッチサイズ, 64*7*7]\n",
    "        x = torch.relu(self.fc1(x))  # [バッチサイズ, 500]\n",
    "        x = self.fc2(x)  # [バッチサイズ, 出力サイズ]\n",
    "        return x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlIqQ9h3kmFs"
   },
   "source": [
    "ネットワークを定義するクラスを以下のように書き換えました．`nn.Conv2d()` は畳み込み層のためのもの，`nn.MaxPool2d()` は最大値プーリングを計算するためのものです．また，``nn.Linear()` はこれまでにも紹介した通り全結合を計算するためのものです．\n",
    "```python\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, OUTPUTSIZE):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2) # 畳み込み層1: 1チャネル入力, 32チャネル出力, カーネルサイズ5, ストライド1, パディング2．\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2) # 畳み込み層2: 32チャネル入力, 64チャネル出力, カーネルサイズ5, ストライド1, パディング2．\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # プーリング層: カーネルサイズ2, ストライド2．\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 500) # 全結合層1: 64*7*7入力, 500出力．\n",
    "        self.fc2 = nn.Linear(500, OUTPUTSIZE) # 全結合層2（出力層）: 500入力, 出力サイズ（クラス数）．\n",
    "    \n",
    "    def forward(self, x): # 入力: [バッチサイズ, 1, 28, 28]\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # [バッチサイズ, 32, 14, 14]\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # [バッチサイズ, 64, 7, 7]\n",
    "        x = x.view(-1, 64 * 7 * 7)  # [バッチサイズ, 64*7*7]\n",
    "        x = torch.relu(self.fc1(x))  # [バッチサイズ, 500]\n",
    "        x = self.fc2(x)  # [バッチサイズ, 出力サイズ]\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdxS1h2srFlw"
   },
   "source": [
    "学習は以下のように進んでいます．パラメータサイズが大きいということは影響していますが，少なくとも MLP より学習が遅いということはないように思えます．\n",
    "```\n",
    "Epoch    1: Training cost=  0.3785 Validation cost=  0.0988\n",
    "Epoch    2: Training cost=  0.0739 Validation cost=  0.0607\n",
    "Epoch    3: Training cost=  0.0476 Validation cost=  0.0510\n",
    "Epoch    4: Training cost=  0.0372 Validation cost=  0.0401\n",
    "Epoch    5: Training cost=  0.0273 Validation cost=  0.0338\n",
    "Epoch    6: Training cost=  0.0221 Validation cost=  0.0398\n",
    "Epoch    7: Training cost=  0.0204 Validation cost=  0.0298\n",
    "Epoch    8: Training cost=  0.0155 Validation cost=  0.0337\n",
    "Epoch    9: Training cost=  0.0112 Validation cost=  0.0368\n",
    "Epoch   10: Training cost=  0.0096 Validation cost=  0.0356\n",
    "Epoch   11: Training cost=  0.0079 Validation cost=  0.0338\n",
    "Epoch   12: Training cost=  0.0063 Validation cost=  0.0365\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YnhFSjmlAOU"
   },
   "source": [
    "最後に，以上で保存したモデルを新たなプログラムで読み込んで，テストデータセットに対する予測をします．以下のように書きます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnaKcy64k_JY"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def main():\n",
    "    # GPUの使用の設定．\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ハイパーパラメータの設定．\n",
    "    MAXEPOCH = 50\n",
    "    MINIBATCHSIZE = 500\n",
    "    PATIENCE = 5\n",
    "\n",
    "    # データの読み込みと前処理．\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    learn_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    # データローダーの設定．\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "    # ネットワークの定義．\n",
    "    model = Network(len(learn_dataset.classes)).to(device)\n",
    "\n",
    "    # モデルの読み込み\n",
    "    model.load_state_dict(torch.load(\"cnn-mnist-model.pt\"))\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # テストデータセットでの推論．\n",
    "    testcost, testacc = 0, 0\n",
    "    total_samples = len(test_dataset)\n",
    "    with torch.no_grad():\n",
    "        for tx, tt in test_loader:\n",
    "            tx = tx.to(device)\n",
    "            ty = model(tx)\n",
    "            tt = tt.to(device)\n",
    "            loss = criterion(ty, tt)\n",
    "            testcost += loss.item()\n",
    "            prediction = ty.argmax(dim=1) # Accuracyを計算するために予測値を計算．\n",
    "            testacc += (prediction == tt).sum().item() / total_samples # Accuracyを計算．\n",
    "    testcost /= len(test_loader)\n",
    "    print(\"Test cost= {:7.4f} Test ACC= {:7.4f}\".format(testcost,testacc))\n",
    "\n",
    "    # テストセットの最初の画像だけに対する推論．\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    for tx, tt in test_loader:\n",
    "        tx, tt = tx.to(device), tt.to(device)\n",
    "        # テストセットの最初の画像を表示．\n",
    "        plt.imshow(tx[0].cpu().squeeze(), cmap=\"gray\")\n",
    "        plt.text(1, 2.5, str(int(tt[0].item())), fontsize=20, color=\"white\")\n",
    "        plt.show()\n",
    "        # 予測．\n",
    "        ty = model(tx)\n",
    "        output_vector = ty.cpu().detach().numpy()  # CPUに移動し、NumPy配列に変換\n",
    "        print(\"Output vector:\", output_vector)\n",
    "        print(\"Argmax of the output vector:\", np.argmax(output_vector))\n",
    "        # 最初の画像の処理のみを行いたいため、ループを抜ける．\n",
    "        break\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, OUTPUTSIZE):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2) # 畳み込み層1: 1チャネル入力, 32チャネル出力, カーネルサイズ5, ストライド1, パディング2．\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2) # 畳み込み層2: 32チャネル入力, 64チャネル出力, カーネルサイズ5, ストライド1, パディング2．\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # プーリング層: カーネルサイズ2, ストライド2．\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 500) # 全結合層1: 64*7*7入力, 500出力．\n",
    "        self.fc2 = nn.Linear(500, OUTPUTSIZE) # 全結合層2（出力層）: 500入力, 出力サイズ（クラス数）．\n",
    "\n",
    "    def forward(self, x): # 入力: [バッチサイズ, 1, 28, 28]\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # [バッチサイズ, 32, 14, 14]\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # [バッチサイズ, 64, 7, 7]\n",
    "        x = x.view(-1, 64 * 7 * 7)  # [バッチサイズ, 64*7*7]\n",
    "        x = torch.relu(self.fc1(x))  # [バッチサイズ, 500]\n",
    "        x = self.fc2(x)  # [バッチサイズ, 出力サイズ]\n",
    "        return x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6AxEJHfuKP3"
   },
   "source": [
    "高い予測性能で予測に成功していることが分かります．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rfC8Kj03omW"
   },
   "source": [
    "```{note}\n",
    "終わりです．\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}